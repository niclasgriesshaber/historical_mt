{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path: /cs/student/msc/csml/2023/ngriessh/historical_mt\n",
      "Results path: /cs/student/msc/csml/2023/ngriessh/historical_mt/results/alphabet/gemma-2-2b-it-bnb-4bit/merged_results.json\n"
     ]
    }
   ],
   "source": [
    "# Base path\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', '..'))\n",
    "\n",
    "# Model Parameters\n",
    "unsloth_model_name = 'unsloth/gemma-2-2b-it-bnb-4bit'\n",
    "company_name = 'alphabet'\n",
    "model_name = unsloth_model_name.split('/')[1]\n",
    "\n",
    "# Results path\n",
    "results_path_file = os.path.join(base_path, 'results', company_name, model_name, 'merged_results.json')\n",
    "\n",
    "# Print paths\n",
    "print('Base path:', base_path)\n",
    "print('Results path:', results_path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Language: Early Modern Bohemian German\n",
      "Target Language: English\n",
      "Translation Direction: DE_to_EN\n",
      "Evaluate ICL: False\n",
      "Evaluate finetuning: True\n",
      "Median Splitting? False\n"
     ]
    }
   ],
   "source": [
    "# Choose source language\n",
    "source_language = \"Early Modern Bohemian German\"\n",
    "target_language = \"English\" if source_language == \"Early Modern Bohemian German\" else \"Early Modern Bohemian German\"\n",
    "\n",
    "# Evaluate finetuning and icl?\n",
    "evaluate_icl = False\n",
    "evaluate_finetuning = True\n",
    "\n",
    "# Median splitting with regard to word count?\n",
    "median_splitting = False\n",
    "# Translation direction is defined depending on the chosen source languag \n",
    "translation_direction = \"DE_to_EN\" if source_language == \"Early Modern Bohemian German\" else \"EN_to_DE\"\n",
    "\n",
    "# Print\n",
    "print(f'Source Language: {source_language}')\n",
    "print(f'Target Language: {target_language}')\n",
    "print(f'Translation Direction: {translation_direction}')\n",
    "print(f'Evaluate ICL: {evaluate_icl}')\n",
    "print(f'Evaluate finetuning: {evaluate_finetuning}')\n",
    "print(f'Median Splitting? {median_splitting}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Results File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file\n",
    "with open(results_path_file, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Create a DataFrame based on the JSON file\n",
    "merged_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Early Modern Bohemian German', 'English', 'DE_to_EN_finetuning',\n",
       "       'EN_to_DE_finetuning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check column names\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Candidate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DE_to_EN_finetuning']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to generate candidate columns based on the conditions\n",
    "def construct_candidate_columns(translation_direction, evaluate_icl, evaluate_finetuning):\n",
    "    shots = ['000', '001', '002', '004'] #, '008', '016', '032', '064', '128']\n",
    "    \n",
    "    # Add shots columns\n",
    "    if evaluate_icl:\n",
    "        if translation_direction == 'DE_to_EN':\n",
    "            candidate_columns = [f'DE_to_EN_{shot}_example_prompt' for shot in shots]\n",
    "        elif translation_direction == 'EN_to_DE':\n",
    "            candidate_columns = [f'EN_to_DE_{shot}_example_prompt' for shot in shots]\n",
    "    \n",
    "    # Add finetuning column\n",
    "    if evaluate_finetuning:\n",
    "        if evaluate_icl:\n",
    "            candidate_columns.append(f'{translation_direction}_finetuning')\n",
    "        else:\n",
    "            candidate_columns = [f'{translation_direction}_finetuning']\n",
    "    \n",
    "    return candidate_columns\n",
    "\n",
    "# You can now concatenate or use these columns as needed\n",
    "candidate_columns = construct_candidate_columns(translation_direction, evaluate_icl, evaluate_finetuning)\n",
    "candidate_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged_df_short: (501, 5)\n",
      "Shape of merged_df_long: (499, 5)\n",
      "Median word count in Early Modern Bohemian German: 73.0\n"
     ]
    }
   ],
   "source": [
    "# Compute word count for the source_language column\n",
    "source_language_word_count = f'{source_language}_word_count'\n",
    "merged_df[source_language_word_count] = merged_df[source_language].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Compute the median word count\n",
    "median_word_count = merged_df[source_language_word_count].median()\n",
    "\n",
    "# Create merged_df_short and merged_df_long based on the median\n",
    "merged_df_short = merged_df[merged_df[source_language_word_count] <= median_word_count]\n",
    "merged_df_long = merged_df[merged_df[source_language_word_count] > median_word_count]\n",
    "\n",
    "#vPrint the shapes of the datasets\n",
    "print(\"Shape of merged_df_short:\", merged_df_short.shape)\n",
    "print(\"Shape of merged_df_long:\", merged_df_long.shape)\n",
    "print(f'Median word count in {source_language}: {median_word_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Early Modern Bohemian German</th>\n",
       "      <th>English</th>\n",
       "      <th>DE_to_EN_finetuning</th>\n",
       "      <th>EN_to_DE_finetuning</th>\n",
       "      <th>Early Modern Bohemian German_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Ein Ambt befehlich an h. Joachim vom Eberha...</td>\n",
       "      <td>1. An manorial court command is to be made to ...</td>\n",
       "      <td>A manorial court's command was issued on appli...</td>\n",
       "      <td>An einen Ambt befehlich an den h.: Jochim Vonn...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ao 1661. Martius. Mildenaw. Christoph blumbrig...</td>\n",
       "      <td>1661. march. Mildenaw. Christoph Blumbrig's co...</td>\n",
       "      <td>March Anno 1661 in mildenau; complaint of Chri...</td>\n",
       "      <td>Anno p 1661 Martij</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schultes, Vnd Schoppen Zue Bernsdorff haben si...</td>\n",
       "      <td>16th July. Schulthess and jurymen in Bernsdorf...</td>\n",
       "      <td>village headman and jurymen in Bernsdorf have ...</td>\n",
       "      <td>Den 16 Julij Scholtess vnd Schöppen Zue Bernßd...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1782. Ist der MildenEicher Scholtes mit dem Di...</td>\n",
       "      <td>1782. The Mildeneichen village headman stood f...</td>\n",
       "      <td>On 30 Sep there was a public manorial court's ...</td>\n",
       "      <td>Der Mieldenaichsche scholtze hat sich bej dem ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3. Novembris. Matz Apelt beschweret sich Vber ...</td>\n",
       "      <td>3. Novembris. Matz Apelt complains against Jac...</td>\n",
       "      <td>On 3 November; Matz Apel complains against Jac...</td>\n",
       "      <td>Den 3 Nouembristes Claget matz Apeltt Vber Jak...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Early Modern Bohemian German  \\\n",
       "0  1. Ein Ambt befehlich an h. Joachim vom Eberha...   \n",
       "4  Ao 1661. Martius. Mildenaw. Christoph blumbrig...   \n",
       "5  Schultes, Vnd Schoppen Zue Bernsdorff haben si...   \n",
       "6  1782. Ist der MildenEicher Scholtes mit dem Di...   \n",
       "8  3. Novembris. Matz Apelt beschweret sich Vber ...   \n",
       "\n",
       "                                             English  \\\n",
       "0  1. An manorial court command is to be made to ...   \n",
       "4  1661. march. Mildenaw. Christoph Blumbrig's co...   \n",
       "5  16th July. Schulthess and jurymen in Bernsdorf...   \n",
       "6  1782. The Mildeneichen village headman stood f...   \n",
       "8  3. Novembris. Matz Apelt complains against Jac...   \n",
       "\n",
       "                                 DE_to_EN_finetuning  \\\n",
       "0  A manorial court's command was issued on appli...   \n",
       "4  March Anno 1661 in mildenau; complaint of Chri...   \n",
       "5  village headman and jurymen in Bernsdorf have ...   \n",
       "6  On 30 Sep there was a public manorial court's ...   \n",
       "8  On 3 November; Matz Apel complains against Jac...   \n",
       "\n",
       "                                 EN_to_DE_finetuning  \\\n",
       "0  An einen Ambt befehlich an den h.: Jochim Vonn...   \n",
       "4                                 Anno p 1661 Martij   \n",
       "5  Den 16 Julij Scholtess vnd Schöppen Zue Bernßd...   \n",
       "6  Der Mieldenaichsche scholtze hat sich bej dem ...   \n",
       "8  Den 3 Nouembristes Claget matz Apeltt Vber Jak...   \n",
       "\n",
       "   Early Modern Bohemian German_word_count  \n",
       "0                                       45  \n",
       "4                                       16  \n",
       "5                                       12  \n",
       "6                                       23  \n",
       "8                                       68  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Early Modern Bohemian German</th>\n",
       "      <th>English</th>\n",
       "      <th>DE_to_EN_finetuning</th>\n",
       "      <th>EN_to_DE_finetuning</th>\n",
       "      <th>Early Modern Bohemian German_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. die lehenß Vnderthanen im Winckel, sollen h...</td>\n",
       "      <td>1. The fief serfs in the Winckel shall hencefo...</td>\n",
       "      <td>The fief-serfs are supposed henceforth for ent...</td>\n",
       "      <td>1. die Lehen Vnterthanen im winckeln sollen hi...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. dz Sie verschienen freytag als den 29 huig ...</td>\n",
       "      <td>1. last Friday, the 29th, they came up to the ...</td>\n",
       "      <td>That on last Friday namely the 29th they came ...</td>\n",
       "      <td>1st Vnterschreibungen am Freytag Verwichener Z...</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es ist Vor.12. iharen Vnnd mehr Zu Oberweigßdo...</td>\n",
       "      <td>12 years ago and more, in Oberweigsdorf, Paul ...</td>\n",
       "      <td>Twelve years ago in Upper Weigsdorff died off ...</td>\n",
       "      <td>Vor Vngefehr Zwantzig Jahren vnd mehr ist Zu o...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2. Ist errinnert Worden alle Undt iede alte re...</td>\n",
       "      <td>2. They were reminded to pay all arrears quick...</td>\n",
       "      <td>The reminder was made that all and every old R...</td>\n",
       "      <td>2. Ist ihnen erinnert worden alle Restiren bal...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vor Vngefehr 14: tagen Kombt des Scholzens Zu ...</td>\n",
       "      <td>About 14 days ago the Scholz's in Bernßdorff's...</td>\n",
       "      <td>About fourteen days ago came before us here at...</td>\n",
       "      <td>Vor Vngefehr Achtage ist des scholzens Zu bern...</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Early Modern Bohemian German  \\\n",
       "1   1. die lehenß Vnderthanen im Winckel, sollen h...   \n",
       "2   1. dz Sie verschienen freytag als den 29 huig ...   \n",
       "3   Es ist Vor.12. iharen Vnnd mehr Zu Oberweigßdo...   \n",
       "7   2. Ist errinnert Worden alle Undt iede alte re...   \n",
       "10  Vor Vngefehr 14: tagen Kombt des Scholzens Zu ...   \n",
       "\n",
       "                                              English  \\\n",
       "1   1. The fief serfs in the Winckel shall hencefo...   \n",
       "2   1. last Friday, the 29th, they came up to the ...   \n",
       "3   12 years ago and more, in Oberweigsdorf, Paul ...   \n",
       "7   2. They were reminded to pay all arrears quick...   \n",
       "10  About 14 days ago the Scholz's in Bernßdorff's...   \n",
       "\n",
       "                                  DE_to_EN_finetuning  \\\n",
       "1   The fief-serfs are supposed henceforth for ent...   \n",
       "2   That on last Friday namely the 29th they came ...   \n",
       "3   Twelve years ago in Upper Weigsdorff died off ...   \n",
       "7   The reminder was made that all and every old R...   \n",
       "10  About fourteen days ago came before us here at...   \n",
       "\n",
       "                                  EN_to_DE_finetuning  \\\n",
       "1   1. die Lehen Vnterthanen im winckeln sollen hi...   \n",
       "2   1st Vnterschreibungen am Freytag Verwichener Z...   \n",
       "3   Vor Vngefehr Zwantzig Jahren vnd mehr ist Zu o...   \n",
       "7   2. Ist ihnen erinnert worden alle Restiren bal...   \n",
       "10  Vor Vngefehr Achtage ist des scholzens Zu bern...   \n",
       "\n",
       "    Early Modern Bohemian German_word_count  \n",
       "1                                       109  \n",
       "2                                       419  \n",
       "3                                        95  \n",
       "7                                       183  \n",
       "10                                      360  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________________\n",
      "Current Dataset: merged_df. Source language is Early Modern Bohemian German.\n",
      "______________________________________________________________________________________________\n",
      "Evaluation of target language English and LLM-generated candidates DE_to_EN_finetuning\n",
      "Corpus-level SacreBLEU score for DE_to_EN_finetuning: 6.409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if median splitting is true\n",
    "if median_splitting:\n",
    "    dataset_splits = [merged_df_short, merged_df_long]\n",
    "    dataset_names = ['merged_df_short', 'merged_df_long']\n",
    "else:\n",
    "    dataset_splits = [merged_df]\n",
    "    dataset_names = ['merged_df']\n",
    "\n",
    "# Compute BLEU scores for both datasets\n",
    "for split, name in zip(dataset_splits, dataset_names):\n",
    "    # Print statement\n",
    "    print('______________________________________________________________________________________________')\n",
    "    print(f'Current Dataset: {name}. Source language is {source_language}.')\n",
    "    print('______________________________________________________________________________________________')\n",
    "\n",
    "    # Create references for split\n",
    "    references = [split[target_language].tolist()]\n",
    "\n",
    "    # Compute corpus-level BLEU scores\n",
    "    for col in candidate_columns:\n",
    "        candidates = split[col].tolist()\n",
    "        print(f'Evaluation of target language {target_language} and LLM-generated candidates {col}')\n",
    "        bleu_score = sacrebleu.corpus_bleu(candidates, references).score\n",
    "        print(f\"Corpus-level SacreBLEU score for {col}: {bleu_score:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Text File to Inspect Translation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file created: translation_inspection_entry.txt\n"
     ]
    }
   ],
   "source": [
    "# Function to generate the inspection text for a specific entry\n",
    "def generate_inspection_text(df, entry_index, translation_directions, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "\n",
    "        # Get the row corresponding to the entry index\n",
    "        row = df.iloc[entry_index]\n",
    "\n",
    "        # Write the German and English translations pairs by Sheilagh Ogilvie\n",
    "        f.write(f\"Entry {entry_index + 1}:\\n\")\n",
    "        f.write(f\"Early Modern Bohemian German (Sheilagh Ogilvie's Transcription): {row['Early Modern Bohemian German']}\\n\")\n",
    "        f.write(f\"English (Sheilagh Ogilvie): {row['English']}\\n\\n\")\n",
    "\n",
    "        # Write the candidate translations for each translation direction\n",
    "        for col in df.columns:\n",
    "            if any(direction in col for direction in translation_directions):\n",
    "                f.write(f\"{col}: {row[col]}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "# Define the translation directions and the entry to inspect\n",
    "translation_directions = ['DE_to_EN', 'EN_to_DE']\n",
    "entry_index = 0\n",
    "\n",
    "# Call the function to generate the text file\n",
    "output_file = 'translation_inspection_entry.txt'\n",
    "generate_inspection_text(merged_df, entry_index, translation_directions, output_file)\n",
    "print(f\"Text file created: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DE_to_EN_004_example_prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/cs/student/projects3/COMP0197/grp3/miniconda_ngriessh/envs/historical_mt_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DE_to_EN_004_example_prompt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Example usage with 'DE_to_EN_128_example_prompt'\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mplot_word_count_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDE_to_EN_004_example_prompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m, in \u001b[0;36mplot_word_count_distribution\u001b[0;34m(df, column_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_word_count_distribution\u001b[39m(df, column_name):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Compute word count for each entry in the specified column\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit()))\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Plotting the histogram of word count distribution\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mhist(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/cs/student/projects3/COMP0197/grp3/miniconda_ngriessh/envs/historical_mt_env/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/cs/student/projects3/COMP0197/grp3/miniconda_ngriessh/envs/historical_mt_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DE_to_EN_004_example_prompt'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute word count and plot the histogram for any column\n",
    "def plot_word_count_distribution(df, column_name):\n",
    "    # Compute word count for each entry in the specified column\n",
    "    df['word_count'] = df[column_name].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Plotting the histogram of word count distribution\n",
    "    plt.hist(df['word_count'], bins=10, edgecolor='black')\n",
    "    plt.title(f'Word Count Distribution for {column_name}')\n",
    "    plt.xlabel('Word Count')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with 'DE_to_EN_128_example_prompt'\n",
    "plot_word_count_distribution(merged_df, 'DE_to_EN_004_example_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
